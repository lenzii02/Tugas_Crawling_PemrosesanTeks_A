{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "from playwright.sync_api import sync_playwright, TimeoutError as PWTimeout\n",
        "\n",
        "# ==================================================\n",
        "# CONFIG - Sesuaikan bila perlu\n",
        "# ==================================================\n",
        "INPUT_CSV = \"google_links_all_pages.csv\"   # harus punya kolom 'url'\n",
        "OUTPUT_CSV = \"quora_opinions.csv\"\n",
        "HEADLESS = False            # agar login/cookie terlihat\n",
        "WAIT_AFTER_ACTION = 10.0    # waktu tunggu setelah klik XPATH_2 (detik)\n",
        "DELAY_BETWEEN_URLS = (1.0, 2.5)\n",
        "SCROLL_WAIT = 10.0          # tunggu setelah scroll (detik)\n",
        "ANSWERS_CLICK_WAIT = 5.0    # tunggu setelah klik tombol \"answers\" (detik)\n",
        "\n",
        "# Paste cookie lengkap di bawah ini (harus full, tidak boleh terpotong)\n",
        "COOKIE_STRING = (\n",
        "    \"m-login=1; m-b=5f0I6CqTwhUnrA3TViu5kg==; m-b_lax=5f0I6CqTwhUnrA3TViu5kg==; \"\n",
        "    \"m-b_strict=5f0I6CqTwhUnrA3TViu5kg==; m-s=iN1d8p2XVQlb_9HNhWBOIg==; m-uid=3109495667; \"\n",
        "    \"m-ql10n_id=https%3A%2F%2Fqsbr.cf2.quoracdn.net%2F-4-l10n_main-30-id-5296391d0f939c4c.translation.json; \"\n",
        "    \"m-theme=dark; m-dynamicFontSize=regular; m-themeStrategy=auto;\"\n",
        ")\n",
        "\n",
        "# ==================================================\n",
        "# XPaths dan CSS Selectors\n",
        "# ==================================================\n",
        "XPATH_1 = \"//button[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'all related')]\"\n",
        "XPATH_2 = \"//div[contains(@class, 'q-text') and contains(@class, 'qu-dynamicFontSize--small') and contains(@class, 'qu-color--gray_dark') and contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'answers')]\"\n",
        "\n",
        "READ_MORE_SPAN_SELECTOR = \".qt_read_more\"\n",
        "OPINION_DIV_SELECTOR = \"div.q-box.spacing_log_answer_content.puppeteer_test_answer_content\"\n",
        "\n",
        "ANSWERS_CSS = (\n",
        "    \".q-click-wrapper.c1nud10e.qu-display--inline-block.qu-tapHighlight--white\"\n",
        "    \".qu-cursor--pointer.qu-hover--textDecoration--underline\"\n",
        ")\n",
        "\n",
        "# ==================================================\n",
        "# Fungsi Utilitas\n",
        "# ==================================================\n",
        "def parse_cookie_string(cookie_string, domain=\".quora.com\"):\n",
        "    cookies = []\n",
        "    parts = [p.strip() for p in cookie_string.split(\";\") if p.strip()]\n",
        "    for p in parts:\n",
        "        if \"=\" not in p:\n",
        "            continue\n",
        "        name, val = p.split(\"=\", 1)\n",
        "        cookies.append({\n",
        "            \"name\": name.strip(),\n",
        "            \"value\": val.strip(),\n",
        "            \"domain\": domain,\n",
        "            \"path\": \"/\",\n",
        "        })\n",
        "    return cookies\n",
        "\n",
        "def read_input_urls(input_csv):\n",
        "    if not os.path.exists(input_csv):\n",
        "        raise FileNotFoundError(f\"Input file not found: {input_csv}\")\n",
        "    urls = []\n",
        "    with open(input_csv, newline=\"\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        if not any(h.lower() == \"url\" for h in reader.fieldnames):\n",
        "            raise ValueError(\"Input CSV must contain 'url' column\")\n",
        "        for row in reader:\n",
        "            u = row.get(\"url\") or row.get(\"URL\") or row.get(\"Url\")\n",
        "            if u:\n",
        "                urls.append(u.strip())\n",
        "    return urls\n",
        "\n",
        "def write_rows_append(output_csv, rows):\n",
        "    file_exists = os.path.exists(output_csv)\n",
        "    with open(output_csv, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        if not file_exists:\n",
        "            writer.writerow([\"url\", \"opinion\"])\n",
        "        for r in rows:\n",
        "            writer.writerow([r[\"url\"], r[\"opinion\"]])\n",
        "\n",
        "def safe_click_locator(page, locator_str, by_xpath=False, timeout=5000):\n",
        "    \"\"\"Try to wait for and click the first element of locator.\"\"\"\n",
        "    try:\n",
        "        locator = page.locator(f\"xpath={locator_str}\") if by_xpath else page.locator(locator_str)\n",
        "        locator.first.wait_for(timeout=timeout)\n",
        "        locator.first.click(timeout=timeout)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def scroll_to_bottom(page):\n",
        "    page.evaluate(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    page.evaluate(\"\"\"() => { window.scrollBy(0, -50); window.scrollBy(0, 50); }\"\"\")\n",
        "\n",
        "def count_opinions_on_page(page):\n",
        "    try:\n",
        "        return page.locator(OPINION_DIV_SELECTOR).count()\n",
        "    except Exception:\n",
        "        return 0\n",
        "\n",
        "def find_and_click_answers_buttons(page):\n",
        "    \"\"\"Cari tombol dengan teks 'answers' dan klik yang pertama.\"\"\"\n",
        "    try:\n",
        "        els = page.locator(ANSWERS_CSS)\n",
        "        n = els.count()\n",
        "        for i in range(n):\n",
        "            el = els.nth(i)\n",
        "            txt = el.inner_text(timeout=2000).strip().lower()\n",
        "            if \"answers\" in txt:\n",
        "                el.scroll_into_view_if_needed(timeout=3000)\n",
        "                el.click(timeout=5000)\n",
        "                return True\n",
        "        return False\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def expand_all_read_more(page):\n",
        "    try:\n",
        "        spans = page.locator(READ_MORE_SPAN_SELECTOR)\n",
        "        count = spans.count()\n",
        "        for i in range(count):\n",
        "            s = spans.nth(i)\n",
        "            s.scroll_into_view_if_needed(timeout=3000)\n",
        "            s.click(timeout=3000)\n",
        "            time.sleep(0.3 + random.random() * 0.6)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "def extract_all_opinions(page):\n",
        "    opinions = []\n",
        "    try:\n",
        "        loc = page.locator(OPINION_DIV_SELECTOR)\n",
        "        cnt = loc.count()\n",
        "        for i in range(cnt):\n",
        "            text = loc.nth(i).inner_text(timeout=5000).strip()\n",
        "            if text:\n",
        "                opinions.append(text)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return opinions\n",
        "\n",
        "# ==================================================\n",
        "# Fungsi Utama\n",
        "# ==================================================\n",
        "def run():\n",
        "    urls = read_input_urls(INPUT_CSV)\n",
        "    print(f\"Found {len(urls)} URLs in {INPUT_CSV}\")\n",
        "\n",
        "    cookies = parse_cookie_string(COOKIE_STRING)\n",
        "    print(f\"Parsed {len(cookies)} cookies (domain .quora.com).\")\n",
        "\n",
        "    with sync_playwright() as p:\n",
        "        browser = p.firefox.launch(headless=HEADLESS)\n",
        "        context = browser.new_context(\n",
        "            user_agent=(\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "                        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "                        \"Chrome/120.0.0.0 Safari/537.36\"),\n",
        "            viewport={\"width\": 1280, \"height\": 900},\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            context.add_cookies(cookies)\n",
        "            print(\"Cookies added to browser context.\")\n",
        "        except Exception as e:\n",
        "            print(\"Warning: failed to add cookies to context:\", e)\n",
        "\n",
        "        page = context.new_page()\n",
        "        time.sleep(1.0)\n",
        "\n",
        "        total_saved = 0\n",
        "        for idx, url in enumerate(urls, start=1):\n",
        "            print(f\"\\n[{idx}/{len(urls)}] Opening: {url}\")\n",
        "            try:\n",
        "                page.goto(url, timeout=30000)\n",
        "            except Exception as e:\n",
        "                print(\"  ! Error loading url:\", e)\n",
        "                continue\n",
        "\n",
        "            while True:\n",
        "                if safe_click_locator(page, XPATH_1, by_xpath=True, timeout=3000):\n",
        "                    print(\"  clicked XPATH_1\")\n",
        "                else:\n",
        "                    print(\"  XPATH_1 not found / skipped\")\n",
        "                time.sleep(1)\n",
        "                if safe_click_locator(page, XPATH_2, by_xpath=True, timeout=3000):\n",
        "                    print(\"  clicked XPATH_2\")\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"  XPATH_2 not found / retrying page reload...\")\n",
        "                    page.goto(url)\n",
        "                    continue\n",
        "\n",
        "            print(f\"  waiting {WAIT_AFTER_ACTION:.1f}s after XPATH clicks...\")\n",
        "            time.sleep(WAIT_AFTER_ACTION)\n",
        "\n",
        "            prev_count = count_opinions_on_page(page)\n",
        "            print(f\"  initial opinion count: {prev_count}\")\n",
        "\n",
        "            while True:\n",
        "                scroll_to_bottom(page)\n",
        "                print(f\"  scrolled to bottom, waiting {SCROLL_WAIT:.1f}s...\")\n",
        "                time.sleep(SCROLL_WAIT)\n",
        "\n",
        "                cur_count = count_opinions_on_page(page)\n",
        "                print(f\"  opinion count after scroll: {cur_count}\")\n",
        "\n",
        "                if cur_count > prev_count:\n",
        "                    print(\"  opinions increased; continue scrolling...\")\n",
        "                    prev_count = cur_count\n",
        "                    time.sleep(0.5 + random.random() * 0.8)\n",
        "                    continue\n",
        "\n",
        "                print(\"  no increase after scroll; trying 'answers' buttons...\")\n",
        "                clicked_answers = find_and_click_answers_buttons(page)\n",
        "                if clicked_answers:\n",
        "                    print(f\"  clicked 'answers' button. waiting {ANSWERS_CLICK_WAIT:.1f}s...\")\n",
        "                    time.sleep(ANSWERS_CLICK_WAIT)\n",
        "                    prev_count = count_opinions_on_page(page)\n",
        "                    continue\n",
        "\n",
        "                print(\"  no more opinions/buttons found.\")\n",
        "                break\n",
        "\n",
        "            print(\"  expanding all 'read more' spans...\")\n",
        "            expand_all_read_more(page)\n",
        "            time.sleep(0.8 + random.random() * 0.6)\n",
        "\n",
        "            opinions = extract_all_opinions(page)\n",
        "            print(f\"  extracted {len(opinions)} opinions from page.\")\n",
        "\n",
        "            if opinions:\n",
        "                rows = [{\"url\": url, \"opinion\": op} for op in opinions]\n",
        "                write_rows_append(OUTPUT_CSV, rows)\n",
        "                total_saved += len(rows)\n",
        "                print(f\"  saved {len(rows)} rows to {OUTPUT_CSV}.\")\n",
        "            else:\n",
        "                print(\"  no opinions found on this page.\")\n",
        "\n",
        "            wait = random.uniform(*DELAY_BETWEEN_URLS)\n",
        "            print(f\"  waiting {wait:.2f}s before next URL...\")\n",
        "            time.sleep(wait)\n",
        "\n",
        "        print(\"\\nDone. Total opinions saved:\", total_saved)\n",
        "\n",
        "        try:\n",
        "            context.close()\n",
        "            browser.close()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "\n",
        "# ==================================================\n",
        "# Entry Point\n",
        "# ==================================================\n",
        "if __name__ == \"__main__\":\n",
        "    run()\n"
      ],
      "metadata": {
        "id": "Ra8DmLmy6jFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYQ9RO-v5aBS",
        "outputId": "8402bfb6-5c62-48e5-8541-e9156d3f4c28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading NLTK data...\n",
            "‚úì Download selesai!\n",
            "\n",
            "üìÇ Membaca file: /content/quora_opinion_israel.xlsx\n",
            "‚úì Berhasil membaca 3658 baris data\n",
            "\n",
            "Menggunakan kolom: 'opinion' untuk preprocessing\n",
            "\n",
            "üîÑ Memproses teks...\n",
            "‚úì Preprocessing selesai!\n",
            "\n",
            "================================================================================\n",
            "CONTOH HASIL PREPROCESSING:\n",
            "================================================================================\n",
            "\n",
            "üìù Data ke-1:\n",
            "ORIGINAL : While I agree that there are morally consistent Jewish-Israelis in Israel. Who don't support abhorrent conduct of Israel towards Palestinians.\n",
            "\n",
            "But th...\n",
            "CLEANED  : agre moral consist jewishisra israel dont support abhorr conduct israel toward palestinian societi major percent vocal genocid toward palestinian dont...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìù Data ke-2:\n",
            "ORIGINAL : Bahai Garden in Haifa\n",
            "\n",
            "Well! Israel is a strong country in defense, safety, research, education, development, tourism, and, of course, Jewish culture....\n",
            "CLEANED  : bahai garden haifa well israel strong countri defens safeti research educ develop tourism cours jewish cultur let us consid part onebyon one thing adv...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìù Data ke-3:\n",
            "ORIGINAL : Country of people trying to survive.\n",
            "\n",
            "Highly smart, intelligent and affluent people who are yet highly religious.\n",
            "\n",
            "As a Hindu myself who have always b...\n",
            "CLEANED  : countri peopl tri surviv highli smart intellig affluent peopl yet highli religi hindu alway persecut deep sympathi jew persecut everi faith earth deve...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìä Statistik:\n",
            "   - Total baris: 3658\n",
            "   - Kolom asli: opinion\n",
            "   - Kolom baru: cleaned_text\n",
            "   - Baris dengan teks kosong setelah cleaning: 14\n",
            "\n",
            "üíæ Menyimpan hasil ke: /content/quora_opinion_israel_CLEANED.xlsx\n",
            "‚úì File berhasil disimpan!\n",
            "\n",
            "üîç Memverifikasi file yang tersimpan...\n",
            "‚úì File terverifikasi dengan 3658 baris\n",
            "‚úì Kolom yang tersimpan: ['opinion', 'cleaned_text']\n",
            "\n",
            "üìÑ Sample dari file yang TERSIMPAN:\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   opinion                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          cleaned_text\n",
            "0  While I agree that there are morally consistent Jewish-Israelis in Israel. Who don't support abhorrent conduct of Israel towards Palestinians.\\n\\nBut that society as a majority (>90 percent) is vocally genocidal towards Palestinians.\\n\\nYou don't even want to get in brain of a individual from a society which as a overwhelming majority believes that use of military force that crosses threshold of genocide, is ‚Äúappropriate‚Äù or ‚Äútoo little‚Äù\\n\\nONLY 1.8 percent of Jewish-Israelis in following poll believe that use of military force by IDF in Gaza was too much.\\n\\nSo when people say;\\n\\nSome fringe right wing lunatics are driving this genocidal policy towards Palestinians.\\nNetanyahu is the cause of all evil.\\nMajority of Jewish-Israelis don't want this towards Gaza.\\n\\nThey are basically living in a delusion or drinking kool-aid of copium, divorced from ground reality that exists in Israel‚Äôs Jewish-Society.\\n\\nEither these people don't know, or don't want to acknowledge this basic ground reality that overwhelming majority of Jewish-Israeli society is supportive of Israel‚Äôs ruling elite‚Äôs policy towards Palestinians.\\n\\nSooner International community realizes this core reality, better will this situation be for Palestinians.  agre moral consist jewishisra israel dont support abhorr conduct israel toward palestinian societi major percent vocal genocid toward palestinian dont even want get brain individu societi overwhelm major believ use militari forc cross threshold genocid ‚Äú appropri ‚Äù ‚Äú littl ‚Äù percent jewishisra follow poll believ use militari forc idf gaza much peopl say fring right wing lunat drive genocid polici toward palestinian netanyahu caus evil major jewishisra dont want toward gaza basic live delus drink koolaid copium divorc ground realiti exist israel ‚Äô jewishsocieti either peopl dont know dont want acknowledg basic ground realiti overwhelm major jewishisra societi support israel ‚Äô rule elit ‚Äô polici toward palestinian sooner intern commun realiz core realiti better situat palestinian\n",
            "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Bahai Garden in Haifa\\n\\nWell! Israel is a strong country in defense, safety, research, education, development, tourism, and, of course, Jewish culture. Let us consider each part one-by-one. But one thing is in advance: Israel is like a western country like the USA. Israel does not impose any restriction on females there. Males and females are treated in an identical manner.\\n\\nNote: I do not know why the quality of pics get reduced. All the places are very beautiful in reality not like these reduced quality pics.\\n\\nDefense. You can judge by a fact that Israel exports defense technologies and equipments,\\n\\n‚Ä¶ (more)                                                                                                                                                                                                                                                                                                                                                                                                                          bahai garden haifa well israel strong countri defens safeti research educ develop tourism cours jewish cultur let us consid part onebyon one thing advanc israel like western countri like usa israel impos restrict femal male femal treat ident manner note know qualiti pic get reduc place beauti realiti like reduc qualiti pic defens judg fact israel export defens technolog equip ‚Ä¶\n",
            "\n",
            "================================================================================\n",
            "‚úÖ PROSES SELESAI!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "\n",
        "# === Unduh NLTK data ===\n",
        "print(\"Downloading NLTK data...\")\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab', quiet=True)\n",
        "print(\"‚úì Download selesai!\\n\")\n",
        "\n",
        "# === Fungsi Preprocessing ===\n",
        "def preprocess_text(text):\n",
        "    if pd.isna(text) or not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Bersihkan HTML tag dan noise\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Case folding\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenizing\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Stopword removal\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# === Baca file Excel ===\n",
        "input_file = '/content/quora_opinion_israel.xlsx'\n",
        "print(f\"üìÇ Membaca file: {input_file}\")\n",
        "df = pd.read_excel(input_file)\n",
        "print(f\"‚úì Berhasil membaca {len(df)} baris data\\n\")\n",
        "\n",
        "# === Pilih kolom teks ===\n",
        "text_column = 'opinion' if 'opinion' in df.columns else df.columns[0]\n",
        "print(f\"Menggunakan kolom: '{text_column}' untuk preprocessing\\n\")\n",
        "\n",
        "# === Jalankan preprocessing ===\n",
        "print(\"üîÑ Memproses teks...\")\n",
        "df['cleaned_text'] = df[text_column].apply(preprocess_text)\n",
        "print(\"‚úì Preprocessing selesai!\\n\")\n",
        "\n",
        "# === Tampilkan hasil ===\n",
        "print(\"=\"*80)\n",
        "print(\"CONTOH HASIL PREPROCESSING:\")\n",
        "print(\"=\"*80)\n",
        "for i in range(min(3, len(df))):\n",
        "    print(f\"\\nüìù Data ke-{i+1}:\")\n",
        "    print(f\"ORIGINAL : {df[text_column].iloc[i][:150]}...\")\n",
        "    print(f\"CLEANED  : {df['cleaned_text'].iloc[i][:150]}...\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "# === Verifikasi sebelum simpan ===\n",
        "print(f\"\\nüìä Statistik:\")\n",
        "print(f\"   - Total baris: {len(df)}\")\n",
        "print(f\"   - Kolom asli: {text_column}\")\n",
        "print(f\"   - Kolom baru: cleaned_text\")\n",
        "print(f\"   - Baris dengan teks kosong setelah cleaning: {(df['cleaned_text'] == '').sum()}\")\n",
        "\n",
        "# === Simpan ke Excel dengan nama berbeda ===\n",
        "output_file = '/content/quora_opinion_israel_CLEANED.xlsx'\n",
        "print(f\"\\nüíæ Menyimpan hasil ke: {output_file}\")\n",
        "\n",
        "# Simpan hanya kolom yang diperlukan untuk memastikan\n",
        "df_output = df[[text_column, 'cleaned_text']].copy()\n",
        "df_output.to_excel(output_file, index=False, engine='openpyxl')\n",
        "\n",
        "print(\"‚úì File berhasil disimpan!\")\n",
        "\n",
        "# === Verifikasi file yang tersimpan ===\n",
        "print(\"\\nüîç Memverifikasi file yang tersimpan...\")\n",
        "df_verify = pd.read_excel(output_file)\n",
        "print(f\"‚úì File terverifikasi dengan {len(df_verify)} baris\")\n",
        "print(f\"‚úì Kolom yang tersimpan: {list(df_verify.columns)}\")\n",
        "\n",
        "# Tampilkan sample dari file yang tersimpan\n",
        "print(\"\\nüìÑ Sample dari file yang TERSIMPAN:\")\n",
        "print(df_verify.head(2).to_string())\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ PROSES SELESAI!\")\n",
        "print(\"=\"*80)"
      ]
    }
  ]
}